{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2890fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain attention mechanisms in one paragraph.\n",
      "Attention mechanisms in natural language processing (NLP) are algorithms that help in detecting and manipulating attention in text data. They are used to extract relevant information from the input text while ignoring irrelevant parts. This is achieved by assigning weights to different parts of the text, allowing the model to focus on the most important information. By doing so, attention mechanisms enable the model to learn more accurate representations of the input text, which can be used for various applications such as language translation, sentiment analysis, and information retrieval.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(base_url=\"http://localhost:8080\", timeout=120)\n",
    "\n",
    "out = client.text_generation(\n",
    "    \"Explain attention mechanisms in one paragraph.\",\n",
    "    max_new_tokens=120,\n",
    ")\n",
    "\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f3ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6e354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (AI Stable)",
   "language": "python",
   "name": "ai311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
